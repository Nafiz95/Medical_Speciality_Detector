{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('transcription_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0   A 23-year-old white female presents with comp...   \n",
       "1           1           Consult for laparoscopic gastric bypass.   \n",
       "2           2           Consult for laparoscopic gastric bypass.   \n",
       "3           3                             2-D M-Mode. Doppler.     \n",
       "4           4                                 2-D Echocardiogram   \n",
       "\n",
       "             medical_specialty                                sample_name  \\\n",
       "0         Allergy / Immunology                         Allergic Rhinitis    \n",
       "1                   Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2                   Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
       "3   Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
       "4   Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
       "\n",
       "                                       transcription  \\\n",
       "0  SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1  PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2  HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  allergy / immunology, allergic rhinitis, aller...  \n",
       "1  bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2  bariatrics, laparoscopic gastric bypass, heart...  \n",
       "3  cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
       "4  cardiovascular / pulmonary, 2-d, doppler, echo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, subset=['transcription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Surgery                          1088\n",
       " Consult - History and Phy.        516\n",
       " Cardiovascular / Pulmonary        371\n",
       " Orthopedic                        355\n",
       " Radiology                         273\n",
       " General Medicine                  259\n",
       " Gastroenterology                  224\n",
       " Neurology                         223\n",
       " SOAP / Chart / Progress Notes     166\n",
       " Urology                           156\n",
       " Obstetrics / Gynecology           155\n",
       " Discharge Summary                 108\n",
       " ENT - Otolaryngology               96\n",
       " Neurosurgery                       94\n",
       " Hematology - Oncology              90\n",
       " Ophthalmology                      83\n",
       " Nephrology                         81\n",
       " Emergency Room Reports             75\n",
       " Pediatrics - Neonatal              70\n",
       " Pain Management                    61\n",
       " Psychiatry / Psychology            53\n",
       " Office Notes                       50\n",
       " Podiatry                           47\n",
       " Dermatology                        29\n",
       " Dentistry                          27\n",
       " Cosmetic / Plastic Surgery         27\n",
       " Letters                            23\n",
       " Physical Medicine - Rehab          21\n",
       " Sleep Medicine                     20\n",
       " Endocrinology                      19\n",
       " Bariatrics                         18\n",
       " IME-QME-Work Comp etc.             16\n",
       " Chiropractic                       14\n",
       " Rheumatology                       10\n",
       " Diets and Nutritions               10\n",
       " Speech - Language                   9\n",
       " Autopsy                             8\n",
       " Lab Medicine - Pathology            8\n",
       " Allergy / Immunology                7\n",
       " Hospice - Palliative Care           6\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.medical_specialty.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    4966\n",
       "Name: transcription, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.transcription.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_medical_specialty(df):\n",
    "    taken = [' Surgery',' Consult - History and Phy.',' Cardiovascular / Pulmonary',' Orthopedic']\n",
    "    medical_specialty = df.medical_specialty.unique().tolist()\n",
    "\n",
    "    for i in range(len(medical_specialty)):\n",
    "        if medical_specialty[i] not in taken:\n",
    "            df = df[df.medical_specialty != medical_specialty[i]]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# df = clean_medical_specialty(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### balancing dataset\n",
    "def balance_dataset(df):\n",
    "    df1 = df[df.medical_specialty == ' Consult - History and Phy.'].iloc[:355]\n",
    "    df2 = df[df.medical_specialty == ' Cardiovascular / Pulmonary'].iloc[:355]\n",
    "    df3 = df[df.medical_specialty == ' Orthopedic'].iloc[:355]\n",
    "    df4 = df[df.medical_specialty == ' Surgery'].iloc[:355]\n",
    "    \n",
    "    frames = [df1, df2, df3, df4]\n",
    "    return pd.concat(frames)\n",
    "\n",
    "df = balance_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1420, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            int64\n",
       "description          object\n",
       "medical_specialty    object\n",
       "sample_name          object\n",
       "transcription        object\n",
       "keywords             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['medical_specialty'] = df['medical_specialty'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"medical_specialty_cat\"] = df[\"medical_specialty\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = df.transcription.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## finding map class to integer value #############\n",
    "class0 = df[df.medical_specialty_cat == 0].iloc[0].medical_specialty\n",
    "class1 = df[df.medical_specialty_cat == 1].iloc[0].medical_specialty\n",
    "class2 = df[df.medical_specialty_cat == 2].iloc[0].medical_specialty\n",
    "class3 = df[df.medical_specialty_cat == 3].iloc[0].medical_specialty\n",
    "classes = {0 : class0, 1 : class1, 2 : class2, 3 : class3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' Cardiovascular / Pulmonary',\n",
       " 1: ' Consult - History and Phy.',\n",
       " 2: ' Orthopedic',\n",
       " 3: ' Surgery'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning and preprocessing\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "corpus = []\n",
    "\n",
    "for i in range(0, len(messages)):\n",
    "    message = re.sub('[^a-zA-Z]', ' ', str(messages[i]))\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    message = [lemmatizer.lemmatize(word) for word in message if not word in stopwords.words('english')]\n",
    "    message = ' '.join(message)\n",
    "    corpus.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the TF-IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer = vectorizer.fit(corpus)\n",
    "X = vectorizer.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1420, 14747)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14747)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform([corpus[0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform([corpus[0]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"medical_specialty\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14747,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model using Naive bayes classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# NB Classifier\n",
    "NB_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_prediction = NB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 1, 2, 3, 1, 0, 1, 3, 2, 1, 1, 1, 3, 1, 1, 1, 3, 2, 0,\n",
       "       3, 2, 3, 0, 2, 1, 3, 3, 0, 2, 0, 0, 2, 2, 0, 1, 1, 2, 0, 1, 3, 2,\n",
       "       3, 2, 2, 3, 2, 0, 1, 1, 3, 0, 1, 1, 1, 1, 0, 3, 1, 3, 3, 1, 1, 1,\n",
       "       3, 0, 0, 3, 1, 1, 1, 0, 2, 1, 1, 2, 0, 0, 3, 2, 3, 2, 1, 2, 1, 1,\n",
       "       2, 2, 1, 2, 1, 2, 1, 3, 1, 1, 1, 2, 1, 3, 3, 1, 1, 2, 3, 2, 2, 3,\n",
       "       1, 0, 1, 1, 1, 2, 3, 2, 3, 1, 1, 3, 3, 0, 2, 1, 3, 1, 2, 1, 3, 0,\n",
       "       2, 1, 1, 1, 1, 1, 3, 2, 2, 1, 1, 0, 3, 3, 1, 3, 2, 1, 1, 2, 3, 0,\n",
       "       3, 3, 2, 1, 3, 3, 1, 1, 1, 0, 0, 1, 3, 3, 3, 3, 3, 1, 1, 3, 2, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 3, 2, 1, 0, 1, 0, 3, 1, 3, 2, 1, 0, 3, 3, 1,\n",
       "       3, 1, 0, 3, 1, 0, 3, 1, 1, 1, 0, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 2,\n",
       "       3, 0, 1, 2, 3, 1, 3, 2, 3, 0, 2, 3, 1, 2, 0, 2, 3, 2, 0, 1, 3, 1,\n",
       "       1, 3, 1, 3, 0, 3, 1, 3, 2, 2, 1, 2, 1, 1, 3, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 2, 3, 3, 2, 2, 2, 2, 1, 3, 1, 3, 0, 2, 1, 1, 0, 2, 0, 1],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# SVC Classifier\n",
    "SVC_model = SVC(kernel='poly').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_prediction = SVC_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 1, 3, 3, 1, 0, 1, 3, 2, 1, 1, 1, 3, 1, 1, 1, 3, 2, 0,\n",
       "       3, 2, 3, 0, 2, 1, 3, 3, 0, 2, 3, 0, 2, 2, 3, 1, 1, 2, 0, 1, 3, 2,\n",
       "       3, 3, 2, 3, 2, 0, 1, 1, 3, 0, 1, 1, 1, 1, 0, 3, 1, 3, 3, 1, 1, 1,\n",
       "       3, 3, 0, 3, 1, 1, 1, 3, 2, 1, 1, 2, 3, 0, 3, 2, 0, 2, 1, 2, 1, 1,\n",
       "       2, 2, 1, 2, 2, 2, 1, 0, 1, 1, 1, 2, 1, 3, 3, 1, 1, 2, 3, 2, 3, 3,\n",
       "       0, 0, 1, 1, 1, 2, 3, 2, 3, 1, 0, 3, 3, 0, 2, 1, 3, 1, 3, 1, 3, 0,\n",
       "       2, 1, 1, 1, 1, 1, 3, 3, 2, 1, 1, 3, 3, 3, 2, 3, 2, 1, 1, 3, 3, 0,\n",
       "       3, 3, 2, 1, 3, 3, 1, 1, 1, 0, 0, 1, 3, 3, 3, 3, 3, 1, 1, 0, 2, 0,\n",
       "       1, 1, 2, 1, 3, 0, 3, 3, 3, 2, 0, 1, 0, 0, 1, 3, 2, 1, 0, 3, 3, 1,\n",
       "       3, 0, 3, 3, 1, 0, 3, 1, 2, 2, 0, 1, 2, 3, 1, 1, 0, 3, 3, 1, 1, 2,\n",
       "       3, 0, 1, 3, 3, 1, 0, 2, 3, 0, 2, 3, 1, 2, 0, 2, 3, 2, 0, 1, 0, 1,\n",
       "       1, 3, 1, 3, 0, 3, 1, 3, 2, 2, 3, 2, 1, 1, 3, 1, 1, 0, 1, 0, 0, 1,\n",
       "       2, 3, 3, 3, 2, 3, 2, 2, 1, 3, 1, 3, 3, 3, 1, 1, 0, 2, 0, 1],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# KNN Classifier\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=4).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_prediction = KNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 3, 1, 3, 3, 1, 0, 1, 0, 2, 1, 1, 1, 3, 0, 1, 1, 3, 2, 0,\n",
       "       3, 1, 3, 0, 2, 1, 3, 3, 0, 2, 3, 0, 2, 2, 3, 1, 1, 0, 0, 1, 3, 2,\n",
       "       3, 2, 2, 3, 2, 0, 1, 1, 3, 0, 1, 1, 1, 1, 0, 0, 1, 3, 3, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 3, 2, 1, 0, 2, 0, 0, 3, 3, 0, 2, 1, 2, 1, 1,\n",
       "       2, 3, 1, 2, 2, 2, 2, 0, 1, 1, 1, 2, 1, 3, 3, 1, 1, 2, 3, 2, 2, 3,\n",
       "       0, 0, 1, 1, 1, 2, 3, 2, 3, 0, 0, 3, 3, 0, 2, 1, 3, 1, 3, 1, 0, 0,\n",
       "       2, 1, 0, 1, 1, 1, 0, 2, 2, 1, 1, 1, 3, 3, 2, 3, 2, 1, 1, 2, 3, 0,\n",
       "       3, 3, 2, 1, 3, 3, 1, 1, 1, 0, 0, 1, 3, 3, 3, 3, 3, 1, 1, 0, 2, 1,\n",
       "       1, 0, 2, 1, 3, 0, 3, 3, 2, 1, 0, 0, 0, 0, 1, 3, 2, 1, 0, 3, 3, 1,\n",
       "       3, 0, 3, 3, 1, 0, 3, 1, 2, 1, 0, 1, 2, 3, 0, 1, 0, 1, 2, 1, 1, 2,\n",
       "       3, 0, 1, 2, 3, 1, 3, 2, 3, 0, 2, 0, 1, 2, 0, 2, 3, 2, 0, 1, 3, 1,\n",
       "       1, 3, 1, 3, 0, 3, 1, 3, 2, 2, 1, 2, 1, 0, 3, 0, 1, 0, 0, 0, 1, 1,\n",
       "       2, 2, 3, 3, 2, 2, 2, 2, 0, 3, 1, 3, 3, 2, 1, 1, 0, 2, 0, 1],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# DecisionTree Classifier\n",
    "DecisionTree_model = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree_prediction = DecisionTree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 3, 1, 3, 3, 1, 0, 0, 3, 2, 1, 1, 3, 0, 1, 1, 1, 3, 2, 0,\n",
       "       3, 2, 3, 2, 2, 1, 3, 3, 0, 2, 0, 0, 2, 2, 3, 1, 1, 2, 0, 0, 3, 2,\n",
       "       0, 3, 1, 3, 2, 2, 1, 2, 3, 1, 1, 1, 1, 3, 0, 2, 0, 0, 3, 0, 0, 1,\n",
       "       3, 0, 0, 2, 1, 1, 1, 3, 2, 1, 0, 2, 0, 0, 2, 2, 0, 2, 1, 2, 1, 0,\n",
       "       2, 2, 1, 1, 1, 3, 1, 0, 2, 1, 2, 2, 1, 2, 0, 3, 0, 2, 3, 2, 1, 3,\n",
       "       0, 0, 1, 1, 1, 2, 3, 2, 0, 1, 0, 3, 3, 0, 2, 0, 3, 2, 1, 1, 3, 1,\n",
       "       2, 1, 0, 1, 1, 1, 3, 2, 2, 0, 0, 0, 3, 3, 2, 3, 2, 1, 1, 3, 3, 0,\n",
       "       3, 3, 2, 1, 0, 3, 1, 1, 1, 3, 0, 1, 3, 0, 3, 3, 3, 0, 1, 0, 2, 0,\n",
       "       1, 2, 2, 1, 1, 0, 3, 3, 2, 2, 0, 1, 0, 0, 1, 2, 2, 0, 0, 3, 3, 1,\n",
       "       3, 0, 3, 0, 0, 0, 3, 2, 2, 2, 0, 1, 2, 3, 0, 1, 1, 3, 3, 1, 1, 2,\n",
       "       3, 3, 1, 2, 3, 0, 0, 2, 0, 0, 3, 3, 1, 2, 0, 2, 3, 2, 0, 1, 0, 0,\n",
       "       1, 3, 1, 3, 2, 3, 1, 3, 2, 2, 3, 2, 1, 1, 3, 0, 1, 2, 0, 3, 0, 1,\n",
       "       2, 3, 3, 3, 3, 3, 2, 2, 1, 0, 2, 0, 0, 3, 1, 1, 0, 3, 0, 1],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisionTree_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Random forest Classifier\n",
    "RandomForest_model=RandomForestClassifier(n_estimators=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_prediction=RandomForest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 1, 3, 3, 1, 3, 1, 3, 2, 1, 1, 1, 3, 1, 1, 1, 3, 2, 0,\n",
       "       3, 2, 3, 1, 2, 1, 3, 3, 0, 2, 0, 0, 2, 2, 0, 1, 1, 2, 0, 1, 3, 2,\n",
       "       3, 3, 2, 3, 2, 0, 1, 1, 3, 0, 1, 1, 1, 1, 0, 3, 1, 3, 3, 1, 1, 1,\n",
       "       3, 0, 0, 3, 1, 1, 1, 0, 2, 1, 1, 2, 3, 0, 3, 2, 0, 2, 1, 2, 1, 1,\n",
       "       2, 2, 1, 1, 2, 2, 1, 0, 1, 1, 1, 2, 1, 3, 3, 3, 1, 2, 3, 2, 2, 3,\n",
       "       0, 0, 1, 1, 1, 3, 3, 2, 3, 1, 0, 3, 3, 0, 2, 1, 3, 1, 2, 1, 3, 0,\n",
       "       2, 1, 0, 1, 1, 1, 3, 3, 2, 0, 1, 0, 3, 3, 2, 3, 2, 1, 1, 3, 3, 0,\n",
       "       3, 3, 2, 1, 3, 3, 1, 1, 1, 0, 0, 1, 3, 3, 3, 3, 3, 1, 1, 0, 2, 0,\n",
       "       1, 1, 2, 1, 1, 0, 3, 3, 3, 2, 0, 1, 0, 0, 1, 3, 2, 1, 0, 3, 3, 1,\n",
       "       3, 0, 3, 3, 1, 0, 3, 1, 2, 2, 0, 1, 2, 3, 1, 1, 1, 3, 3, 1, 1, 2,\n",
       "       3, 0, 1, 3, 3, 1, 0, 2, 3, 0, 3, 3, 1, 2, 0, 2, 3, 2, 0, 1, 3, 1,\n",
       "       1, 3, 1, 3, 0, 3, 1, 3, 2, 2, 3, 2, 1, 0, 3, 0, 1, 0, 1, 0, 0, 1,\n",
       "       2, 3, 3, 3, 2, 3, 2, 2, 1, 3, 1, 3, 0, 3, 1, 1, 0, 2, 0, 1],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################LogisticRegression Classifier\n",
    "LogisticRegression_model = LogisticRegression(solver='liblinear', C=10.0, random_state=0).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression_prediction = LogisticRegression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 1, 3, 3, 1, 0, 1, 3, 2, 1, 1, 1, 3, 1, 1, 1, 3, 2, 0,\n",
       "       3, 2, 3, 0, 2, 1, 3, 3, 0, 2, 0, 0, 2, 2, 0, 1, 1, 2, 0, 1, 3, 2,\n",
       "       3, 3, 2, 3, 2, 0, 1, 1, 3, 0, 1, 1, 1, 1, 0, 0, 1, 3, 3, 1, 1, 1,\n",
       "       3, 0, 0, 3, 1, 1, 1, 0, 2, 1, 1, 2, 3, 0, 3, 2, 0, 2, 1, 2, 1, 1,\n",
       "       2, 2, 1, 1, 2, 2, 2, 0, 1, 1, 1, 2, 1, 3, 3, 2, 1, 2, 3, 2, 2, 3,\n",
       "       0, 0, 1, 1, 1, 2, 3, 2, 3, 1, 0, 3, 3, 0, 2, 1, 3, 1, 2, 2, 3, 0,\n",
       "       2, 1, 0, 1, 1, 1, 3, 2, 2, 0, 1, 0, 3, 3, 2, 3, 2, 1, 1, 3, 3, 0,\n",
       "       3, 3, 2, 1, 3, 3, 1, 1, 1, 0, 0, 1, 3, 3, 3, 0, 3, 1, 1, 0, 2, 0,\n",
       "       1, 1, 2, 1, 1, 0, 3, 3, 2, 2, 0, 1, 0, 0, 1, 3, 2, 1, 0, 3, 3, 1,\n",
       "       3, 0, 3, 3, 1, 0, 3, 1, 2, 2, 0, 1, 2, 3, 0, 1, 0, 3, 3, 1, 1, 2,\n",
       "       3, 0, 1, 2, 3, 1, 0, 2, 3, 0, 2, 3, 1, 2, 0, 2, 3, 2, 0, 1, 0, 2,\n",
       "       2, 3, 1, 3, 0, 3, 1, 3, 2, 2, 3, 2, 1, 0, 3, 0, 1, 0, 0, 0, 0, 1,\n",
       "       2, 3, 3, 3, 2, 3, 2, 2, 1, 3, 1, 3, 0, 3, 0, 1, 0, 2, 0, 1],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes f1_score: 0.7639912981887098\n",
      "KNN f1_score: 0.7473816977209109\n",
      "SVC f1_score: 0.7499168442801605\n",
      "Decision tree f1_score: 0.5822290911830412\n",
      "Random_forest f1_score: 0.7042185370638033\n",
      "LogisticRegression f1_score: 0.7615167201836806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "print('naive_bayes f1_score: {}'.format(f1_score(y_test,naive_bayes_prediction, average='macro')))\n",
    "print('KNN f1_score: {}'.format(f1_score(y_test,KNN_prediction, average='macro')))\n",
    "print('SVC f1_score: {}'.format(f1_score(y_test,SVC_prediction, average='macro')))\n",
    "print('Decision tree f1_score: {}'.format(f1_score(y_test,decisionTree_prediction, average='macro')))\n",
    "print('Random_forest f1_score: {}'.format(f1_score(y_test,random_forest_prediction, average='macro')))\n",
    "print('LogisticRegression f1_score: {}'.format(f1_score(y_test,LogisticRegression_prediction, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes accuracy: 0.7711267605633803\n",
      "KNN accuracy: 0.75\n",
      "SVC accuracy: 0.7535211267605634\n",
      "DecisionTree accuracy: 0.5845070422535211\n",
      "Random_forest accuracy: 0.7112676056338029\n",
      "LogisticRegression accuracy: 0.7640845070422535\n"
     ]
    }
   ],
   "source": [
    "print('naive_bayes accuracy: {}'.format(accuracy_score(y_test, naive_bayes_prediction)))\n",
    "print('KNN accuracy: {}'.format(accuracy_score(y_test, KNN_prediction)))\n",
    "print('SVC accuracy: {}'.format(accuracy_score(y_test, SVC_prediction)))\n",
    "print('DecisionTree accuracy: {}'.format(accuracy_score(y_test, decisionTree_prediction)))\n",
    "print('Random_forest accuracy: {}'.format(accuracy_score(y_test, random_forest_prediction)))\n",
    "print('LogisticRegression accuracy: {}'.format(accuracy_score(y_test, LogisticRegression_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes recall_score: 0.7679563492063493\n",
      "KNN recall_score: 0.7471289146289146\n",
      "SVC recall_score: 0.7515787215787216\n",
      "Decision tree recall_score: 0.5822361647361647\n",
      "Random_forest recall_score: 0.705725546975547\n",
      "LogisticRegression recall_score: 0.7617771342771342\n"
     ]
    }
   ],
   "source": [
    "print('naive_bayes recall_score: {}'.format(recall_score(y_test,naive_bayes_prediction, average='macro')))\n",
    "print('KNN recall_score: {}'.format(recall_score(y_test,KNN_prediction, average='macro')))\n",
    "print('SVC recall_score: {}'.format(recall_score(y_test,SVC_prediction, average='macro')))\n",
    "print('Decision tree recall_score: {}'.format(recall_score(y_test,decisionTree_prediction, average='macro')))\n",
    "print('Random_forest recall_score: {}'.format(recall_score(y_test,random_forest_prediction, average='macro')))\n",
    "print('LogisticRegression recall_score: {}'.format(recall_score(y_test,LogisticRegression_prediction, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes precision_score: 0.8054501094871154\n",
      "KNN precision_score: 0.7545627285539974\n",
      "SVC precision_score: 0.7627630967390653\n",
      "Decision tree precision_score: 0.5824324324324325\n",
      "Random_forest precision_score: 0.719736732185266\n",
      "LogisticRegression precision_score: 0.7671847979634299\n"
     ]
    }
   ],
   "source": [
    "print('naive_bayes precision_score: {}'.format(precision_score(y_test,naive_bayes_prediction, average='macro')))\n",
    "print('KNN precision_score: {}'.format(precision_score(y_test,KNN_prediction, average='macro')))\n",
    "print('SVC precision_score: {}'.format(precision_score(y_test,SVC_prediction, average='macro')))\n",
    "print('Decision tree precision_score: {}'.format(precision_score(y_test,decisionTree_prediction, average='macro')))\n",
    "print('Random_forest precision_score: {}'.format(precision_score(y_test,random_forest_prediction, average='macro')))\n",
    "print('LogisticRegression precision_score: {}'.format(precision_score(y_test,LogisticRegression_prediction, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, 20,  0, 13],\n",
       "       [ 0, 74,  0,  0],\n",
       "       [ 0, 16, 46,  1],\n",
       "       [ 2,  1, 12, 60]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, naive_bayes_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier f1_score: 0.7219646247264613\n"
     ]
    }
   ],
   "source": [
    "print('GradientBoostingClassifier f1_score: {}'.format(f1_score(y_test,GBC_prediction, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier accuracy: 0.7253521126760564\n"
     ]
    }
   ],
   "source": [
    "print('GradientBoostingClassifier accuracy: {}'.format(accuracy_score(y_test, GBC_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier f1_score: 0.7172961992497626\n",
      "XGBClassifier accuracy: 0.7183098591549296\n"
     ]
    }
   ],
   "source": [
    "print('XGBClassifier f1_score: {}'.format(f1_score(y_test,XGB_prediction, average='macro')))\n",
    "print('XGBClassifier accuracy: {}'.format(accuracy_score(y_test, GBC_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"models/KNN_model.pkl\",\"wb\")\n",
    "pickle.dump(KNN_model, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# saving models\n",
    "with open('models/NB_model.pickle', 'wb') as NB_modelhandle:\n",
    "    pickle.dump(NB_model, NB_modelhandle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    NB_modelhandle.close()\n",
    "\n",
    "with open('models/SVC_model.pickle', 'wb') as SVC_modelhandle:\n",
    "    pickle.dump(SVC_model, SVC_modelhandle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    SVC_modelhandle.close()\n",
    "    \n",
    "with open('models/KNN_model.pickle', 'wb') as KNN_modelhandle:\n",
    "    pickle.dump(KNN_model, KNN_modelhandle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    KNN_modelhandle.close()\n",
    "    \n",
    "with open('models/DecisionTree_model.pickle', 'wb') as DecisionTree_modelhandle:\n",
    "    pickle.dump(DecisionTree_model, DecisionTree_modelhandle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    DecisionTree_modelhandle.close()\n",
    "    \n",
    "with open('models/RandomForest_model.pickle', 'wb') as RandomForest_modelhandle:\n",
    "    pickle.dump(RandomForest_model, RandomForest_modelhandle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    RandomForest_modelhandle.close()\n",
    "    \n",
    "with open('models/LogisticRegression_model.pickle', 'wb') as LogisticRegression_modelhandle:\n",
    "    pickle.dump(LogisticRegression_model, LogisticRegression_modelhandle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    LogisticRegression_modelhandle.close()\n",
    "    \n",
    "with open('models/vectorizer.pickle', 'wb') as vectorizerhandle:\n",
    "    pickle.dump(vectorizer, vectorizerhandle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    vectorizerhandle.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "[[0.         0.         0.78980693 0.         0.         0.\n",
      "  0.         0.61335554]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# list of text documents\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\",\n",
    "\t\t\"The dog.\",\n",
    "\t\t\"The fox\"]\n",
    "test_text = 'the fox is bad'\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# encode document\n",
    "vector = vectorizer.transform([test_text])\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/vectorizer.pickle', 'rb') as vectorizerhandle:\n",
    "    classical_vectorizer = pickle.load(vectorizerhandle)\n",
    "    vectorizerhandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform([corpus[0]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
